{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d36b7ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 - Building the CNN\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e545d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3339 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# Flow training images in batches of 128 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'flowers',  # This is the source directory for training images\n",
    "        target_size=(200, 200),  # All images will be resized to 200 x 200\n",
    "        batch_size=batch_size,\n",
    "        # Specify the classes explicitly\n",
    "        classes = ['daisy','rose','sunflower','dandelion'],\n",
    "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
    "        class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13dc5bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 200x 200 with 3 bytes color\n",
    "    # The first convolution\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(200, 200, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fourth convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fifth convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a dense layer\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # 128 neuron in the fully-connected layer\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    # 5 output neurons for 5 classes with the softmax activation\n",
    "    tf.keras.layers.Dense(4, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f72e4b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 198, 198, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 99, 99, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 97, 97, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 48, 48, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 46, 46, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 23, 23, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 21, 21, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 10, 10, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 4, 4, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               131200    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 229,156\n",
      "Trainable params: 229,156\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e526a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.001),\n",
    "              metrics=['acc'])\n",
    "\n",
    "total_sample=train_generator.n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe583087",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_14164\\2091447111.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "104/104 [==============================] - 326s 3s/step - loss: 1.1168 - acc: 0.5135\n",
      "Epoch 2/30\n",
      "104/104 [==============================] - 315s 3s/step - loss: 0.8746 - acc: 0.6601\n",
      "Epoch 3/30\n",
      "104/104 [==============================] - 274s 3s/step - loss: 0.7575 - acc: 0.7097\n",
      "Epoch 4/30\n",
      "104/104 [==============================] - 210s 2s/step - loss: 0.6894 - acc: 0.7345\n",
      "Epoch 5/30\n",
      "104/104 [==============================] - 258s 2s/step - loss: 0.6420 - acc: 0.7690\n",
      "Epoch 6/30\n",
      "104/104 [==============================] - 281s 3s/step - loss: 0.5865 - acc: 0.7862\n",
      "Epoch 7/30\n",
      "104/104 [==============================] - 246s 2s/step - loss: 0.5392 - acc: 0.8062\n",
      "Epoch 8/30\n",
      "104/104 [==============================] - 148s 1s/step - loss: 0.4936 - acc: 0.8177\n",
      "Epoch 9/30\n",
      "104/104 [==============================] - 141s 1s/step - loss: 0.4681 - acc: 0.8301\n",
      "Epoch 10/30\n",
      "104/104 [==============================] - 141s 1s/step - loss: 0.4100 - acc: 0.8431\n",
      "Epoch 11/30\n",
      "104/104 [==============================] - 140s 1s/step - loss: 0.3697 - acc: 0.8639\n",
      "Epoch 12/30\n",
      "104/104 [==============================] - 140s 1s/step - loss: 0.3251 - acc: 0.8778\n",
      "Epoch 13/30\n",
      "104/104 [==============================] - 140s 1s/step - loss: 0.2912 - acc: 0.8972\n",
      "Epoch 14/30\n",
      "104/104 [==============================] - 138s 1s/step - loss: 0.2569 - acc: 0.9120\n",
      "Epoch 15/30\n",
      "104/104 [==============================] - 140s 1s/step - loss: 0.2287 - acc: 0.9171\n",
      "Epoch 16/30\n",
      "104/104 [==============================] - 139s 1s/step - loss: 0.1726 - acc: 0.9371\n",
      "Epoch 17/30\n",
      "104/104 [==============================] - 138s 1s/step - loss: 0.1590 - acc: 0.9456\n",
      "Epoch 18/30\n",
      "104/104 [==============================] - 138s 1s/step - loss: 0.1225 - acc: 0.9592\n",
      "Epoch 19/30\n",
      "104/104 [==============================] - 140s 1s/step - loss: 0.1189 - acc: 0.9589\n",
      "Epoch 20/30\n",
      "104/104 [==============================] - 154s 1s/step - loss: 0.0969 - acc: 0.9673\n",
      "Epoch 21/30\n",
      "104/104 [==============================] - 164s 2s/step - loss: 0.0796 - acc: 0.9749\n",
      "Epoch 22/30\n",
      "104/104 [==============================] - 159s 2s/step - loss: 0.0812 - acc: 0.9722\n",
      "Epoch 23/30\n",
      "104/104 [==============================] - 143s 1s/step - loss: 0.0647 - acc: 0.9800\n",
      "Epoch 24/30\n",
      "104/104 [==============================] - 140s 1s/step - loss: 0.0615 - acc: 0.9809\n",
      "Epoch 25/30\n",
      "104/104 [==============================] - 140s 1s/step - loss: 0.0606 - acc: 0.9776\n",
      "Epoch 26/30\n",
      "104/104 [==============================] - 140s 1s/step - loss: 0.0505 - acc: 0.9864\n",
      "Epoch 27/30\n",
      "104/104 [==============================] - 144s 1s/step - loss: 0.0444 - acc: 0.9876\n",
      "Epoch 28/30\n",
      "104/104 [==============================] - 166s 2s/step - loss: 0.0527 - acc: 0.9855\n",
      "Epoch 29/30\n",
      "104/104 [==============================] - 150s 1s/step - loss: 0.0455 - acc: 0.9903\n",
      "Epoch 30/30\n",
      "104/104 [==============================] - 170s 2s/step - loss: 0.0474 - acc: 0.9873\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 30\n",
    "\n",
    "history = model.fit_generator(\n",
    "        train_generator, \n",
    "        steps_per_epoch=int(total_sample/batch_size),  \n",
    "        epochs=n_epochs,\n",
    "        verbose=1)\n",
    "\n",
    "model.save('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f90fe775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step\n",
      "ROSE\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras_preprocessing import image\n",
    "import easygui\n",
    "image11 = easygui.fileopenbox()\n",
    "test_image = image.load_img(image11, target_size = (200,200))\n",
    "#test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "result = model.predict(test_image)\n",
    "\n",
    "if result[0][1] == 1:\n",
    "    print(\"ROSE\")\n",
    "elif result[0][0] == 1:\n",
    "    print(\"DAISY\")\n",
    "elif result[0][2] == 1:\n",
    "    print(\"SUNFLOWER\")\n",
    "elif result[0][3] == 1:\n",
    "    print(\"DANDELION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06100754",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
